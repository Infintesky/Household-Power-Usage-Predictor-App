{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "3brax54gc92mdv5yf4bog8",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "# 2D Design Template"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "boi0tuojn2lv0a7psqnphm",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "# Overview\n",
                "\n",
                "The purpose of this project is for you to apply what you have learnt in this course. This includes working with data and visualizing it, create model of linear regression, as well as using metrics to measure the accuracy of your model. \n",
                "\n",
                "Please find the project handout description in the following [link](https://edimension.sutd.edu.sg/webapps/blackboard/content/listContent.jsp?course_id=_5582_1&content_id=_200537_1).\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "4h8s09nq04kexe620dnp0j",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "## Deliverables\n",
                "\n",
                "You need to submit this Jupyter notebook together with the dataset into Vocareum. Use the template in this notebook to work on this project. You are free to edit or add more cells if needed"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "d4oukr61l4snjxaqy2gn3l"
            },
            "source": [
                "## Students Submission\n",
                "*Include a short sentence summarizing each member’s contribution.*\n",
                "\n",
                "Student's Name:\n",
                "- Chen Shixiong - 1009260: Cleaning dataset\n",
                "- Yeo Owen - 1009253: Found dataset\n",
                "- Low Wei Yang - 1008921: Build model\n",
                "- Lee Yi Xiang - 1009335: Evaluated model\n",
                "- Arman Parkash - 1009174: Perform feature and target preparation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "sugx7cl409ty0kwq55dua"
            },
            "source": [
                "### Problem Statement\n",
                "\n",
                "- Background description of the problem\n",
                "\n",
                "With energy demand rising and weather patterns growing more erratic, accurate forecasting of electricity usage has become a critical priority for cities like London. As temperature, humidity, and wind speed shift throughout the year, energy consumption patterns follow suit — affecting everything from heating systems in winter to cooling loads during the warmer months.\n",
                "\n",
                "This project uses Multiple Linear Regression (MLR) to develop a predictive model of household energy consumption in kilowatt-hours (kWh), based on three key environmental factors: average temperature, humidity, and wind speed. These variables were selected for their measurable impact on energy demand and for the availability of reliable historical data.\n",
                "\n",
                "By building and comparing the MLR model in Python, the project aims to understand how well these variables explain fluctuations in electricity use in London. The goal is to produce a model that is statistically robust, reproducible, and scalable — offering potential use cases for energy providers, city planners, and policy-makers seeking to optimise energy resources and improve sustainability."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- User Persona\n",
                "\n",
                "Name: David Rahman\n",
                "\n",
                "Age: 45\n",
                "\n",
                "Role: Senior Urban Energy Planner\n",
                "\n",
                "Organization: Greater London Authority (GLA)\n",
                "\n",
                "Location: City Hall, London\n",
                "\n",
                "Background:\n",
                "\n",
                "David has over 15 years of experience in sustainable urban planning. His current focus is on integrating energy efficiency into city infrastructure to meet London’s climate goals and reduce strain on the electricity grid.\n",
                "\n",
                "Goals & Responsibilities:\n",
                "\n",
                "Ensure London's energy systems are resilient and prepared for seasonal demand\n",
                "\n",
                "Support the city’s transition to net-zero emissions by 2030\n",
                "\n",
                "Make data-driven decisions for urban development and housing retrofits\n",
                "\n",
                "Collaborate with energy providers to predict and reduce peak load pressures\n",
                "\n",
                "Allocate funding for sustainability projects based on real impact potential\n",
                "\n",
                "Pain Points:\n",
                "\n",
                "Energy demand predictions often rely on outdated or generalised models\n",
                "\n",
                "Difficulty in aligning short-term weather shifts with long-term infrastructure planning\n",
                "\n",
                "Lacks granular, season-specific data to guide targeted energy interventions\n",
                "\n",
                "Needs a scalable and reproducible system to evaluate energy usage across boroughs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Problem Statement using “how might we ...” statement\n",
                "\n",
                "How might we predict household energy consumption in London using average temperature, humidity, and wind speed, to improve energy planning and protect vulnerable communities from the effects of climate variability."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "d88z0vga22yzgsnze3ql",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Dataset\n",
                "\n",
                "- Describe your dataset.\n",
                "- Put the link to the sources of your raw dataset.\n",
                "- Put python codes for loading the data into pandas dataframe(s). The data should be the raw data downloaded from the source. No pre-processing using any software (excel, python, etc) yet. Include this dataset in your submission\n",
                "- Explain each column of your dataset (can use comment or markdown)\n",
                "- State which column is the dependent variable (target) and explain how it is related to your problem statement\n",
                "- State which columns are the independent variables (features) and describe your hypothesis on why these features can predict the target variable\n",
                "\n",
                "[`LCL.csv`](https://data.4tu.nl/datasets/fbbe775b-48d8-469f-a39b-b64488bfd6fd) : \n",
                "\n",
                "- This dataset contains half hourly smart meter measurements of 4443 households, obtained during the Low Carbon London project, during 2013.\n",
                "\n",
                "- Columns:\n",
                "\n",
                "    DateTime: The date and time of power usage record.\n",
                "\n",
                "    MAC\\d{6}: Household labels' power usage where measurements are in kWh (energy consumption) for the preceding half hour.\n",
                "\n",
                "\n",
                "[`all_weather_data.csv`](https://www.kaggle.com/datasets/jakewright/2m-daily-weather-history-uk?resource=download): \n",
                "\n",
                "- This dataset contains historical weather data from various locations across the UK, spanning from 2009 to 2024. Each entry records the weather conditions for a specific day, providing insights into temperature, rain, humidity, cloud cover, wind speed, and wind direction. The data is useful for analyzing weather patterns and trends over time.\n",
                "\n",
                "- Columns:\n",
                "\n",
                "    location: The name of the location (e.g., Holywood, Ardkeen).\n",
                "\n",
                "    date: The date of the weather record (format: YYYY-MM-DD).\n",
                "\n",
                "    min_temp (°C): The minimum temperature recorded on that day (in degrees Celsius).\n",
                "\n",
                "    max_temp (°C): The maximum temperature recorded on that day (in degrees Celsius).\n",
                "\n",
                "    rain (mm): The amount of rainfall recorded (in millimeters).\n",
                "\n",
                "    humidity (%): The percentage of humidity.\n",
                "\n",
                "    cloud_cover (%): The percentage of cloud cover.\n",
                "\n",
                "    wind_speed (km/h): The wind speed recorded (in kilometers per hour).\n",
                "\n",
                "    wind_direction: The direction of the wind (e.g., N, SSE, WSW).\n",
                "\n",
                "    wind_direction_numerical: The numerical representation of the wind direction (e.g., 90.0 for east)\n",
                "\n",
                "\n",
                "Feature - X data (Independent): Average temperature, Humidity and Wind Speed\n",
                "\n",
                "Target - Y data (Dependent): Power Usage"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Import Necessary Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import TypeAlias\n",
                "from typing import Optional, Any\n",
                "\n",
                "Number: TypeAlias = int | float\n",
                "\n",
                "import warnings\n",
                "import math\n",
                "\n",
                "warnings.filterwarnings('ignore', category=FutureWarning, message='.*Dtype inference.*')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.axes as axes\n",
                "import seaborn as sns\n",
                "from IPython.display import display"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Import necessary functions from cohort problem sets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def normalize_z(array: np.ndarray, columns_means: Optional[np.ndarray]=None,\n",
                "                columns_stds: Optional[np.ndarray]=None) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
                "    assert columns_means is None or columns_means.shape == (1, array.shape[1])\n",
                "    assert columns_stds is None or columns_stds.shape == (1, array.shape[1])\n",
                "\n",
                "    if columns_means is None:\n",
                "        columns_means = array.mean(axis=0).reshape(1, -1)\n",
                "\n",
                "    if columns_stds is None:\n",
                "        columns_stds = array.std(axis=0).reshape(1, -1)\n",
                "\n",
                "    out: np.ndarray = (array - columns_means) / columns_stds\n",
                "\n",
                "    assert out.shape == array.shape\n",
                "    assert columns_means.shape == (1, array.shape[1])\n",
                "    assert columns_stds.shape == (1, array.shape[1])\n",
                "    return out, columns_means, columns_stds\n",
                "\n",
                "\n",
                "def get_features_targets(df: pd.DataFrame,\n",
                "                         feature_names: list[str],\n",
                "                         target_names: list[str]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
                "    df_feature: pd.DataFrame = df[feature_names] # if feature_names is not list[str] type and just str, then we will get Series and not Dataframe\n",
                "    df_target: pd.DataFrame = df[target_names]\n",
                "    return df_feature, df_target\n",
                "\n",
                "\n",
                "def prepare_feature(np_feature: np.ndarray) -> np.ndarray:\n",
                "    cols: int = np_feature.shape[1]\n",
                "    X: np.ndarray = np.concatenate((np.ones((np_feature.shape[0],1)), np_feature), axis = 1 ) # axis = 1 is to concatenate column wise\n",
                "    return X\n",
                "\n",
                "\n",
                "def predict_linreg(array_feature: np.ndarray, beta: np.ndarray,\n",
                "                   means: Optional[np.ndarray]=None,\n",
                "                   stds: Optional[np.ndarray]=None) -> np.ndarray:\n",
                "    assert means is None or means.shape == (1, array_feature.shape[1])\n",
                "    assert stds is None or stds.shape == (1, array_feature.shape[1])\n",
                "    norm_data, _, _ = normalize_z(array_feature, means, stds)\n",
                "    X: np.ndarray = prepare_feature(norm_data)\n",
                "    result = calc_linreg(X, beta)\n",
                "    assert result.shape == (array_feature.shape[0], 1)\n",
                "    return result\n",
                "\n",
                "\n",
                "def calc_linreg(X: np.ndarray, beta: np.ndarray) -> np.ndarray:\n",
                "    result = np.matmul(X, beta)\n",
                "    assert result.shape == (X.shape[0], 1)\n",
                "    return result\n",
                "\n",
                "\n",
                "def compute_cost_linreg(X: np.ndarray, y: np.ndarray, beta: np.ndarray) -> np.ndarray:\n",
                "    m = X.shape[0]\n",
                "    predicted_y = calc_linreg(X, beta)\n",
                "    error = predicted_y - y\n",
                "    error_sq = np.matmul(error.T, error)\n",
                "    J = (1/(2*m)) * error_sq\n",
                "    assert J.shape == (1, 1)\n",
                "    return np.squeeze(J)\n",
                "\n",
                "\n",
                "def gradient_descent_linreg(X: np.ndarray, y: np.ndarray, beta: np.ndarray,\n",
                "                            alpha: float, num_iters: int) -> tuple[np.ndarray, np.ndarray]:\n",
                "    m = X.shape[0]\n",
                "    J_storage = np.zeros ((num_iters, 1))\n",
                "    for n in range(num_iters):\n",
                "        deriv: np.ndarray = np.matmul(X.T, (calc_linreg(X, beta) - y))\n",
                "        beta = beta - alpha * (1/m) * deriv\n",
                "        J_storage[n] = compute_cost_linreg(X, y, beta)\n",
                "\n",
                "    assert beta.shape == (X.shape[1], 1)\n",
                "    assert J_storage.shape == (num_iters, 1)\n",
                "    return beta, J_storage\n",
                "\n",
                "\n",
                "def split_data(df_feature: pd.DataFrame, df_target: pd.DataFrame,\n",
                "               random_state: Optional[int]=None,\n",
                "               test_size: float=0.5) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
                "    index = df_feature.index\n",
                "\n",
                "    if random_state is not None:\n",
                "        np.random.seed(random_state)\n",
                "\n",
                "    rows_test_size = int(test_size * len(index))\n",
                "\n",
                "    # Sample the test index dataset\n",
                "    test_index = np.random.choice(index, rows_test_size, replace = False)\n",
                "    train_index = index.drop(test_index)\n",
                "\n",
                "    # Select data for the output\n",
                "    df_feature_train = df_feature.loc[train_index, :]\n",
                "    df_feature_test = df_feature.loc[test_index,:]\n",
                "\n",
                "    df_target_train = df_target.loc[train_index,:]\n",
                "    df_target_test = df_target.loc[test_index,:]\n",
                "\n",
                "    return df_feature_train, df_feature_test, df_target_train, df_target_test\n",
                "\n",
                "\n",
                "# just wrap all the code in CS4 in a function\n",
                "def build_model_linreg(df_feature_train: pd.DataFrame,\n",
                "                       df_target_train: pd.DataFrame,\n",
                "                       beta: Optional[np.ndarray] = None,\n",
                "                       alpha: float = 0.01,\n",
                "                       iterations: int = 1500) -> tuple[dict[str, Any], np.ndarray]:\n",
                "    # check if initial beta values are given\n",
                "    if beta is None:\n",
                "        beta = np.zeros((df_feature_train.shape[1]+1, 1)) # add one dimension to the feature_train array because of the b0 coefficient\n",
                "    assert beta.shape == (df_feature_train.shape[1]+1, 1) # to make sure if beta argument is given, then it conforms to the shape of the feature train\n",
                "\n",
                "    array_feature_train_z, means, stds = normalize_z(df_feature_train.to_numpy())\n",
                "\n",
                "    # prepare the X matrix and the target vector as ndarray\n",
                "    X: np.ndarray = prepare_feature(array_feature_train_z)\n",
                "    target: np.ndarray = df_target_train.to_numpy()\n",
                "    beta, J_storage = gradient_descent_linreg(X, target, beta, alpha, iterations)\n",
                "    # store the output in model dictionary\n",
                "    model = {\"beta\": beta, \"means\":means, \"stds\": stds}\n",
                "\n",
                "    # assert the shapes\n",
                "    assert model[\"beta\"].shape == (df_feature_train.shape[1] + 1, 1) # make sure that beta vector is d by 1\n",
                "    assert model[\"means\"].shape == (1, df_feature_train.shape[1]) # make sure that the means vector is also d-1 by 1 (1 per feature)\n",
                "    assert model[\"stds\"].shape == (1, df_feature_train.shape[1])  # make sure that the stds vector is also d-1 by 1 (1 per feature)\n",
                "    assert J_storage.shape == (iterations, 1) # make sure we have recorded #iterations of error\n",
                "    return model, J_storage\n",
                "\n",
                "\n",
                "def r2_score(y: np.ndarray, ypred: np.ndarray) -> float:\n",
                "    res = np.sum((y - ypred)**2)\n",
                "    tot = np.sum((y - y.mean())**2)\n",
                "    return 1 - res / tot\n",
                "\n",
                "\n",
                "def mean_squared_error(target: np.ndarray, pred: np.ndarray) -> float:\n",
                "    return np.sum((target - pred)**2)/target.shape[0]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Loading Raw Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df1 = pd.read_csv('./LCL_2013.csv')\n",
                "\n",
                "df1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df2 = pd.read_csv('./all_weather_data.csv')\n",
                "\n",
                "df2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "mnalotvuhwah3o3d16kul",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Clean & Analyze your data\n",
                "Use python code to:\n",
                "- Clean your data\n",
                "- Calculate Descriptive Statistics and other statistical analysis\n",
                "- Visualization with meaningful analysis description"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### `LCL.csv` (Average Household Power Usage)\n",
                "\n",
                "1. Compute average energy average usage across all households.\n",
                "2. Convert energy usage data into daily scale."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a proper copy of the dataframe and ensure clean dtypes\n",
                "df1_pp = df1.iloc[:-1].copy()\n",
                "\n",
                "# Drop columns where there are households with readings that are NaN\n",
                "df1_pp = df1_pp.dropna(axis='columns', how='any')\n",
                "\n",
                "# Convert DateTime column into datetime format with explicit parameters\n",
                "df1_pp.loc[:, 'DateTime'] = pd.to_datetime(df1_pp['DateTime'], format='mixed', errors='coerce')\n",
                "\n",
                "# Set index and ensure it's properly typed\n",
                "df1_pp = df1_pp.set_index('DateTime')\n",
                "\n",
                "# Resample by day ('D') and sum each column (i.e. each household)\n",
                "df_daily = df1_pp.resample('D').sum()\n",
                "\n",
                "# Reset index so 'DateTime' becomes a column again\n",
                "df_daily = df_daily.reset_index()\n",
                "\n",
                "# Exclude non-household columns (e.g., 'DateTime')\n",
                "mac_columns = [col for col in df_daily.columns if col.startswith('MAC')]\n",
                "\n",
                "# Compute row-wise average across all MAC* columns\n",
                "df_daily['Household Average'] = df_daily[mac_columns].mean(axis=1, skipna=True)\n",
                "\n",
                "# Create final dataframe with just DateTime and average\n",
                "df_daily_average = df_daily[['DateTime', 'Household Average']].copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "display(df_daily_average), display(df_daily_average.describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### `all_weather_data.csv` (Weather stats in London)\n",
                "\n",
                "1. Filter data to include only records from the year 2013.\n",
                "2. Select London data only."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df2_pp = df2.copy()\n",
                "\n",
                "# Filter for London AND year 2013 in one operation\n",
                "df2_london_2013 = df2_pp[\n",
                "    (df2_pp['location'] == 'London') &\n",
                "    (pd.to_datetime(df2_pp['date']).dt.year == 2013)\n",
                "].copy()\n",
                "\n",
                "df2_london_2013['average_temp °c'] = (df2_london_2013['min_temp °c'] + df2_london_2013['max_temp °c']) / 2\n",
                "\n",
                "# Ensure date column is datetime format\n",
                "df2_london_2013['date'] = pd.to_datetime(df2_london_2013['date'])\n",
                "\n",
                "column_order = [\n",
                "    'location', 'date', 'min_temp °c', 'average_temp °c', 'max_temp °c',\n",
                "    'rain mm', 'humidity %', 'cloud_cover %', 'wind_speed km/h',\n",
                "    'wind_direction', 'wind_direction_numerical'\n",
                "]\n",
                "\n",
                "# Reorder the dataframe\n",
                "df2_london_2013 = df2_london_2013[column_order]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "display(df2_london_2013), display(df2_london_2013.describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Seasonal Classification\n",
                "\n",
                "1. Correlate both datasets base on date.\n",
                "2. Segment dataset by season for further analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add season classification\n",
                "def get_season(date):\n",
                "    \"\"\"\n",
                "    Classify date into seasons based on meteorological seasons:\n",
                "    - Winter: December, January, February\n",
                "    - Spring: March, April, May\n",
                "    - Summer: June, July, August\n",
                "    - Fall/Autumn: September, October, November\n",
                "    \"\"\"\n",
                "    month = date.month\n",
                "    if month in [12, 1, 2]:\n",
                "        return 'Winter'\n",
                "    elif month in [3, 4, 5]:\n",
                "        return 'Spring'\n",
                "    elif month in [6, 7, 8]:\n",
                "        return 'Summer'\n",
                "    else:  # months 9, 10, 11\n",
                "        return 'Fall'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply season classification using .loc to avoid warning\n",
                "df_daily_average.loc[:, 'Season'] = df_daily_average['DateTime'].apply(get_season)\n",
                "\n",
                "# Split data into seasonal dataframes\n",
                "winter_data = df_daily_average[df_daily_average['Season'] == 'Winter'].copy()\n",
                "spring_data = df_daily_average[df_daily_average['Season'] == 'Spring'].copy()\n",
                "summer_data = df_daily_average[df_daily_average['Season'] == 'Summer'].copy()\n",
                "fall_data = df_daily_average[df_daily_average['Season'] == 'Fall'].copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add season column\n",
                "df2_london_2013['season'] = df2_london_2013['date'].apply(get_season)\n",
                "\n",
                "# Split data into seasonal dataframes\n",
                "winter_weather = df2_london_2013[df2_london_2013['season'] == 'Winter'].copy()\n",
                "spring_weather = df2_london_2013[df2_london_2013['season'] == 'Spring'].copy()\n",
                "summer_weather = df2_london_2013[df2_london_2013['season'] == 'Summer'].copy()\n",
                "fall_weather = df2_london_2013[df2_london_2013['season'] == 'Fall'].copy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "winter_data = pd.merge(\n",
                "    winter_data,           # energy data with 'DateTime' and 'Household Average'\n",
                "    winter_weather,        # weather data with 'date' and 'average_temp'\n",
                "    left_on='DateTime',    # date column in energy data\n",
                "    right_on='date',       # date column in weather data\n",
                "    how='inner'            # only dates that exist in both datasets\n",
                ")\n",
                "\n",
                "spring_data = pd.merge(\n",
                "    spring_data,           # energy data with 'DateTime' and 'Household Average'\n",
                "    spring_weather,        # weather data with 'date' and 'average_temp'\n",
                "    left_on='DateTime',    # date column in energy data\n",
                "    right_on='date',       # date column in weather data\n",
                "    how='inner'            # only dates that exist in both datasets\n",
                ")\n",
                "\n",
                "summer_data = pd.merge(\n",
                "    summer_data,           # energy data with 'DateTime' and 'Household Average'\n",
                "    summer_weather,        # weather data with 'date' and 'average_temp'\n",
                "    left_on='DateTime',    # date column in energy data\n",
                "    right_on='date',       # date column in weather data\n",
                "    how='inner'            # only dates that exist in both datasets\n",
                ")\n",
                "\n",
                "fall_data = pd.merge(\n",
                "    fall_data,           # energy data with 'DateTime' and 'Household Average'\n",
                "    fall_weather,        # weather data with 'date' and 'average_temp'\n",
                "    left_on='DateTime',    # date column in energy data\n",
                "    right_on='date',       # date column in weather data\n",
                "    how='inner'            # only dates that exist in both datasets\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "display(winter_data), display(winter_data.describe())\n",
                "display(spring_data), display(spring_data.describe())\n",
                "display(summer_data), display(summer_data.describe())\n",
                "display(fall_data), display(fall_data.describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Model Analysis"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Features and Target Preparation\n",
                "\n",
                "Prepare features and target for model training.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "FEATURE_NAMES = [\"min_temp °c\", \"average_temp °c\", \"max_temp °c\", \"rain mm\", \"humidity %\", \"cloud_cover %\", \"wind_speed km/h\", \"wind_direction_numerical\"]\n",
                "TARGET_NAMES = [\"Household Average\"]\n",
                "\n",
                "df_feature_winter, df_target_winter = get_features_targets(winter_data, FEATURE_NAMES, TARGET_NAMES)\n",
                "df_feature_spring, df_target_spring = get_features_targets(spring_data, FEATURE_NAMES, TARGET_NAMES)\n",
                "df_feature_summer, df_target_summer = get_features_targets(summer_data, FEATURE_NAMES, TARGET_NAMES)\n",
                "df_feature_fall, df_target_fall = get_features_targets(fall_data, FEATURE_NAMES, TARGET_NAMES)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "array_feature_winter = df_feature_winter.to_numpy()\n",
                "array_feature_spring = df_feature_spring.to_numpy()\n",
                "array_feature_summer = df_feature_summer.to_numpy()\n",
                "array_feature_fall = df_feature_fall.to_numpy()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_features_winter: pd.DataFrame = pd.DataFrame(array_feature_winter, columns=df_feature_winter.columns)\n",
                "display(df_features_winter.describe()), display(df_target_winter.describe())\n",
                "\n",
                "df_features_spring: pd.DataFrame = pd.DataFrame(array_feature_spring, columns=df_feature_spring.columns)\n",
                "display(df_features_spring.describe()), display(df_target_spring.describe())\n",
                "\n",
                "df_features_summer: pd.DataFrame = pd.DataFrame(array_feature_summer, columns=df_feature_summer.columns)\n",
                "display(df_features_summer.describe()), display(df_target_summer.describe())\n",
                "\n",
                "df_features_fall: pd.DataFrame = pd.DataFrame(array_feature_fall, columns=df_feature_fall.columns)\n",
                "display(df_features_fall.describe()), display(df_target_fall.describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Building Model\n",
                "\n",
                "Use python code to build your model. Give explanation on this process.\n",
                "\n",
                "Cost Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# put Python code to build your model\n",
                "X_winter: np.ndarray = prepare_feature(df_features_winter.to_numpy())\n",
                "target_winter: np.ndarray = df_target_winter.to_numpy().reshape(-1,1)\n",
                "beta_winter: np.ndarray = np.zeros((X_winter.shape[1],1))\n",
                "J_winter: np.ndarray = compute_cost_linreg(X_winter, target_winter, beta_winter)\n",
                "print(J_winter)\n",
                "\n",
                "\n",
                "X_spring: np.ndarray = prepare_feature(df_features_spring.to_numpy())\n",
                "target_spring: np.ndarray = df_target_spring.to_numpy().reshape(-1,1)\n",
                "beta_spring: np.ndarray = np.zeros((X_spring.shape[1],1))\n",
                "J_spring: np.ndarray = compute_cost_linreg(X_spring, target_spring, beta_spring)\n",
                "print(J_spring)\n",
                "\n",
                "\n",
                "X_summer: np.ndarray = prepare_feature(df_features_summer.to_numpy())\n",
                "target_summer: np.ndarray = df_target_summer.to_numpy().reshape(-1,1)\n",
                "beta_summer: np.ndarray = np.zeros((X_summer.shape[1],1))\n",
                "J_summer: np.ndarray = compute_cost_linreg(X_summer, target_summer, beta_summer)\n",
                "print(J_summer)\n",
                "\n",
                "\n",
                "X_fall: np.ndarray = prepare_feature(df_features_fall.to_numpy())\n",
                "target_fall: np.ndarray = df_target_fall.to_numpy().reshape(-1,1)\n",
                "beta_fall: np.ndarray = np.zeros((X_fall.shape[1],1))\n",
                "J_fall: np.ndarray = compute_cost_linreg(X_fall, target_fall, beta_fall)\n",
                "print(J_fall)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Gradient descent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "iterations: int = 1500\n",
                "'''\"\n",
                "We chose a very small learning rate (alpha = 0.00001) because our input data (like temperature, humidity, etc.) was not scaled properly. \n",
                "Without scaling, some values were much bigger than others, which made the model unstable when learning too fast.\n",
                "If we used a higher learning rate, the model's predictions would \"jump around\" too much and quickly become useless,\n",
                "and we will get results like nan (not a number).\n",
                "So, to keep the model stable, we had to slow it down by using a much smaller learning rate.\n",
                "'''\n",
                "alpha: float = 0.00001\n",
                "\n",
                "beta_winter: np.ndarray = np.zeros((X_winter.shape[1],1))\n",
                "beta_spring: np.ndarray = np.zeros((X_spring.shape[1],1))\n",
                "beta_summer: np.ndarray = np.zeros((X_summer.shape[1],1))\n",
                "beta_fall: np.ndarray = np.zeros((X_fall.shape[1],1))\n",
                "\n",
                "\n",
                "beta_winter, J_storage_winter = gradient_descent_linreg(X_winter, target_winter, beta_winter, alpha, iterations)\n",
                "print('beta_winter: \\n', beta_winter)\n",
                "print('J_storage_winter: \\n', J_storage_winter)\n",
                "\n",
                "beta_spring, J_storage_spring = gradient_descent_linreg(X_spring, target_spring, beta_spring, alpha, iterations)\n",
                "print('beta_spring: \\n', beta_spring)\n",
                "print('J_storage_spring: \\n', J_storage_spring)\n",
                "\n",
                "beta_summer, J_storage_summer = gradient_descent_linreg(X_summer, target_summer, beta_summer, alpha, iterations)\n",
                "print('beta_summer: \\n', beta_summer)\n",
                "print('J_storage_summer: \\n', J_storage_summer)\n",
                "\n",
                "beta_fall, J_storage_fall = gradient_descent_linreg(X_fall, target_fall, beta_fall, alpha, iterations)\n",
                "print('beta_fall: \\n', beta_fall)\n",
                "print('J_storage_fall: \\n', J_storage_fall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(J_storage_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(J_storage_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(J_storage_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(J_storage_fall)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Predict Linear Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Call predict()\n",
                "pred_winter: np.ndarray = predict_linreg(df_features_winter.to_numpy(), beta_winter)\n",
                "\n",
                "# Change target to numpy array\n",
                "target_winter: np.ndarray = df_target_winter.to_numpy()\n",
                "\n",
                "print(\"Winter\")\n",
                "print(pred_winter[0], pred_winter[1], pred_winter[2])\n",
                "print(target_winter[0], target_winter[1], target_winter[2])\n",
                "print(pred_winter.mean(), pred_winter.std())\n",
                "\n",
                "\n",
                "\n",
                "# Call predict()\n",
                "pred_spring: np.ndarray = predict_linreg(df_features_spring.to_numpy(), beta_spring)\n",
                "\n",
                "# Change target to numpy array\n",
                "target_spring: np.ndarray = df_target_spring.to_numpy()\n",
                "\n",
                "print(\"Spring\")\n",
                "print(pred_spring[0], pred_spring[1], pred_spring[2])\n",
                "print(target_spring[0], target_spring[1], target_spring[2])\n",
                "print(pred_spring.mean(), pred_spring.std())\n",
                "\n",
                "\n",
                "\n",
                "# Call predict()\n",
                "pred_summer: np.ndarray = predict_linreg(df_features_summer.to_numpy(), beta_summer)\n",
                "\n",
                "# Change target to numpy array\n",
                "target_summer: np.ndarray = df_target_summer.to_numpy()\n",
                "\n",
                "print(\"Summer\")\n",
                "print(pred_summer[0], pred_summer[1], pred_summer[2])\n",
                "print(target_summer[0], target_summer[1], target_summer[2])\n",
                "print(pred_summer.mean(), pred_summer.std())\n",
                "\n",
                "\n",
                "\n",
                "# Call predict()\n",
                "pred_fall: np.ndarray = predict_linreg(df_features_fall.to_numpy(), beta_fall)\n",
                "\n",
                "# Change target to numpy array\n",
                "target_fall: np.ndarray = df_target_fall.to_numpy()\n",
                "\n",
                "print(\"Fall\")\n",
                "print(pred_fall[0], pred_fall[1], pred_fall[2])\n",
                "print(target_fall[0], target_fall[1], target_fall[2])\n",
                "print(pred_fall.mean(), pred_fall.std())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "Evaluating the Model\n",
                "\n",
                "- Describe the metrics of your choice\n",
                "- Evaluate your model performance\n",
                "\n",
                "Splitting Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split the data set into training and test\n",
                "df_features_train_winter, df_features_test_winter, df_target_train_winter, df_target_test_winter = split_data(df_features_winter, df_target_winter, random_state=100, test_size=0.3)\n",
                "# call build_model_linreg() function\n",
                "model_winter, J_storage_winter = build_model_linreg(df_features_train_winter, df_target_train_winter)\n",
                "# call the predict_linreg() method\n",
                "pred_winter: np.ndarray = predict_linreg(df_features_test_winter.to_numpy(), model_winter['beta'], model_winter['means'], model_winter['stds'])\n",
                "\n",
                "\n",
                "# Split the data set into training and test\n",
                "df_features_train_spring, df_features_test_spring, df_target_train_spring, df_target_test_spring = split_data(df_features_spring, df_target_spring, random_state=100, test_size=0.3)\n",
                "# call build_model_linreg() function\n",
                "model_spring, J_storage_spring = build_model_linreg(df_features_train_spring, df_target_train_spring)\n",
                "# call the predict_linreg() method\n",
                "pred_spring: np.ndarray = predict_linreg(df_features_test_spring.to_numpy(), model_spring['beta'], model_spring['means'], model_spring['stds'])\n",
                "\n",
                "\n",
                "# Split the data set into training and test\n",
                "df_features_train_summer, df_features_test_summer, df_target_train_summer, df_target_test_summer = split_data(df_features_summer, df_target_summer, random_state=100, test_size=0.3)\n",
                "# call build_model_linreg() function\n",
                "model_summer, J_storage_summer = build_model_linreg(df_features_train_summer, df_target_train_summer)\n",
                "# call the predict_linreg() method\n",
                "pred_summer: np.ndarray = predict_linreg(df_features_test_summer.to_numpy(), model_summer['beta'], model_summer['means'], model_summer['stds'])\n",
                "\n",
                "\n",
                "# Split the data set into training and test\n",
                "df_features_train_fall, df_features_test_fall, df_target_train_fall, df_target_test_fall = split_data(df_features_fall, df_target_fall, random_state=100, test_size=0.3)\n",
                "# call build_model_linreg() function\n",
                "model_fall, J_storage_fall = build_model_linreg(df_features_train_fall, df_target_train_fall)\n",
                "# call the predict_linreg() method\n",
                "pred_fall: np.ndarray = predict_linreg(df_features_test_fall.to_numpy(), model_fall['beta'], model_fall['means'], model_fall['stds'])\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "R<sup>2</sup> Score (Coefficient of Determination)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target_winter: np.ndarray = df_target_test_winter.to_numpy()\n",
                "r2_winter: float = r2_score(target_winter, pred_winter)\n",
                "\n",
                "target_spring: np.ndarray = df_target_test_spring.to_numpy()\n",
                "r2_spring: float = r2_score(target_spring, pred_spring)\n",
                "\n",
                "target_summer: np.ndarray = df_target_test_summer.to_numpy()\n",
                "r2_summer: float = r2_score(target_summer, pred_summer)\n",
                "\n",
                "target_fall: np.ndarray = df_target_test_fall.to_numpy()\n",
                "r2_fall: float = r2_score(target_fall, pred_fall)\n",
                "\n",
                "print('r2_winter:', round(r2_winter,3))\n",
                "print('r2_spring:', round(r2_spring,3))\n",
                "print('r2_summer:', round(r2_summer,3))\n",
                "print('r2_fall:', round(r2_fall,3))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Mean Square Error & Root Mean Squared Error"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mse_winter: float = mean_squared_error(target_winter, pred_winter)\n",
                "rmse_winter: float = math.sqrt(mse_winter)\n",
                "\n",
                "mse_spring: float = mean_squared_error(target_spring, pred_spring)\n",
                "rmse_spring: float = math.sqrt(mse_spring)\n",
                "\n",
                "mse_summer: float = mean_squared_error(target_summer, pred_summer)\n",
                "rmse_summer: float = math.sqrt(mse_summer)\n",
                "\n",
                "mse_fall: float = mean_squared_error(target_fall, pred_fall)\n",
                "rmse_fall: float = math.sqrt(mse_fall)\n",
                "\n",
                "print(f'mse_winter: {round(mse_winter,3)}, rmse_winter: {round(rmse_winter,3)}')\n",
                "print(f'mse_spring: {round(mse_spring,3)}, rmse_spring: {round(rmse_spring,3)}')\n",
                "print(f'mse_summer: {round(mse_summer,3)}, rmse_summer: {round(rmse_summer,3)}')\n",
                "print(f'mse_fall: {round(mse_fall,3)}, rmse_fall: {round(rmse_fall,3)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "hnrervpc9ood1trkd0ku3c",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Improving the Model\n",
                "\n",
                "- Improve the models by performing any data processing techniques or hyperparameter tuning.\n",
                "- You can repeat the steps above to show the improvement as compared to the previous performance\n",
                "\n",
                "Note:\n",
                "- You should not change or add dataset at this step\n",
                "- You are allowed to use library such as sklearn for data processing (NOT for building model)\n",
                "- Make sure to have the same test dataset so the results are comparable with the previous model \n",
                "- If you perform hyperparameter tuning, it will require you to split your training data further into train and validation dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "5spy1s2ji3345y1uunm7es",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Features and Target Preparation\n",
                "\n",
                "Prepare features and target for model training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellIdentifier": "x1leu6b5aph6akcqy9stf4",
                "collapsed": true,
                "jupyter": {
                    "outputs_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# put Python code to prepare your features and target\n",
                "FEATURE_NAMES = [\"average_temp °c\", \"humidity %\", \"wind_speed km/h\"]\n",
                "TARGET_NAMES = [\"Household Average\"]\n",
                "\n",
                "df_feature_winter, df_target_winter = get_features_targets(winter_data, FEATURE_NAMES, TARGET_NAMES)\n",
                "df_feature_spring, df_target_spring = get_features_targets(spring_data, FEATURE_NAMES, TARGET_NAMES)\n",
                "df_feature_summer, df_target_summer = get_features_targets(summer_data, FEATURE_NAMES, TARGET_NAMES)\n",
                "df_feature_fall, df_target_fall = get_features_targets(fall_data, FEATURE_NAMES, TARGET_NAMES)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "array_feature_winter, _, _ = normalize_z(df_feature_winter.to_numpy())\n",
                "array_feature_spring, _, _ = normalize_z(df_feature_spring.to_numpy())\n",
                "array_feature_summer, _, _ = normalize_z(df_feature_summer.to_numpy())\n",
                "array_feature_fall, _, _ = normalize_z(df_feature_fall.to_numpy())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_features_winter: pd.DataFrame = pd.DataFrame(array_feature_winter, columns=df_feature_winter.columns)\n",
                "display(df_features_winter.describe()), display(df_target_winter.describe())\n",
                "\n",
                "df_features_spring: pd.DataFrame = pd.DataFrame(array_feature_spring, columns=df_feature_spring.columns)\n",
                "display(df_features_spring.describe()), display(df_target_spring.describe())\n",
                "\n",
                "df_features_summer: pd.DataFrame = pd.DataFrame(array_feature_summer, columns=df_feature_summer.columns)\n",
                "display(df_features_summer.describe()), display(df_target_summer.describe())\n",
                "\n",
                "df_features_fall: pd.DataFrame = pd.DataFrame(array_feature_fall, columns=df_feature_fall.columns)\n",
                "display(df_features_fall.describe()), display(df_target_fall.describe())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_winter[\"average_temp °c\"], df_target_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_winter[\"humidity %\"], df_target_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_winter[\"wind_speed km/h\"], df_target_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_spring[\"average_temp °c\"], df_target_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_spring[\"humidity %\"], df_target_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_spring[\"wind_speed km/h\"], df_target_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_summer[\"average_temp °c\"], df_target_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_summer[\"humidity %\"], df_target_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_summer[\"wind_speed km/h\"], df_target_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_fall[\"average_temp °c\"], df_target_fall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_fall[\"humidity %\"], df_target_fall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set()\n",
                "plt.scatter(df_features_fall[\"wind_speed km/h\"], df_target_fall)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "wyzlafckek8h4t0nsibxr",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Building Model\n",
                "\n",
                "Use python code to build your model. Give explanation on this process."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Cost Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellIdentifier": "nkl339hcc1g22vccuogg2o",
                "collapsed": true,
                "jupyter": {
                    "outputs_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# put Python code to build your model\n",
                "X_winter: np.ndarray = prepare_feature(df_features_winter.to_numpy())\n",
                "target_winter: np.ndarray = df_target_winter.to_numpy()\n",
                "beta_winter: np.ndarray = np.zeros((4,1))\n",
                "J_winter: np.ndarray = compute_cost_linreg(X_winter, target_winter, beta_winter)\n",
                "print(J_winter)\n",
                "\n",
                "\n",
                "X_spring: np.ndarray = prepare_feature(df_features_spring.to_numpy())\n",
                "target_spring: np.ndarray = df_target_spring.to_numpy()\n",
                "beta_spring: np.ndarray = np.zeros((4,1))\n",
                "J_spring: np.ndarray = compute_cost_linreg(X_spring, target_spring, beta_spring)\n",
                "print(J_spring)\n",
                "\n",
                "\n",
                "X_summer: np.ndarray = prepare_feature(df_features_summer.to_numpy())\n",
                "target_summer: np.ndarray = df_target_summer.to_numpy()\n",
                "beta_summer: np.ndarray = np.zeros((4,1))\n",
                "J_summer: np.ndarray = compute_cost_linreg(X_summer, target_summer, beta_summer)\n",
                "print(J_summer)\n",
                "\n",
                "\n",
                "X_fall: np.ndarray = prepare_feature(df_features_fall.to_numpy())\n",
                "target_fall: np.ndarray = df_target_fall.to_numpy()\n",
                "beta_fall: np.ndarray = np.zeros((4,1))\n",
                "J_fall: np.ndarray = compute_cost_linreg(X_fall, target_fall, beta_fall)\n",
                "print(J_fall)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Gradient descent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "iterations: int = 1500\n",
                "alpha: float = 0.01\n",
                "\n",
                "beta_winter: np.ndarray = np.zeros((4,1))\n",
                "beta_spring: np.ndarray = np.zeros((4,1))\n",
                "beta_summer: np.ndarray = np.zeros((4,1))\n",
                "beta_fall: np.ndarray = np.zeros((4,1))\n",
                "\n",
                "beta_winter, J_storage_winter = gradient_descent_linreg(X_winter, target_winter, beta_winter, alpha, iterations)\n",
                "print('beta_winter: \\n', beta_winter)\n",
                "print('J_storage_winter: \\n', J_storage_winter)\n",
                "\n",
                "beta_spring, J_storage_spring = gradient_descent_linreg(X_spring, target_spring, beta_spring, alpha, iterations)\n",
                "print('beta_spring: \\n', beta_spring)\n",
                "print('J_storage_spring: \\n', J_storage_spring)\n",
                "\n",
                "beta_summer, J_storage_summer = gradient_descent_linreg(X_summer, target_summer, beta_summer, alpha, iterations)\n",
                "print('beta_summer: \\n', beta_summer)\n",
                "print('J_storage_summer: \\n', J_storage_summer)\n",
                "\n",
                "beta_fall, J_storage_fall = gradient_descent_linreg(X_fall, target_fall, beta_fall, alpha, iterations)\n",
                "print('beta_fall: \\n', beta_fall)\n",
                "print('J_storage_fall: \\n', J_storage_fall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(J_storage_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(J_storage_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(J_storage_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(J_storage_fall)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Predict Linear Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Call predict()\n",
                "pred_winter: np.ndarray = predict_linreg(df_features_winter.to_numpy(), beta_winter)\n",
                "\n",
                "# Change target to numpy array\n",
                "target_winter: np.ndarray = df_target_winter.to_numpy()\n",
                "\n",
                "print(\"Winter\")\n",
                "print(pred_winter[0], pred_winter[1], pred_winter[2])\n",
                "print(target_winter[0], target_winter[1], target_winter[2])\n",
                "print(pred_winter.mean(), pred_winter.std())\n",
                "\n",
                "\n",
                "\n",
                "# Call predict()\n",
                "pred_spring: np.ndarray = predict_linreg(df_features_spring.to_numpy(), beta_spring)\n",
                "\n",
                "# Change target to numpy array\n",
                "target_spring: np.ndarray = df_target_spring.to_numpy()\n",
                "\n",
                "print(\"Spring\")\n",
                "print(pred_spring[0], pred_spring[1], pred_spring[2])\n",
                "print(target_spring[0], target_spring[1], target_spring[2])\n",
                "print(pred_spring.mean(), pred_spring.std())\n",
                "\n",
                "\n",
                "\n",
                "# Call predict()\n",
                "pred_summer: np.ndarray = predict_linreg(df_features_summer.to_numpy(), beta_summer)\n",
                "\n",
                "# Change target to numpy array\n",
                "target_summer: np.ndarray = df_target_summer.to_numpy()\n",
                "\n",
                "print(\"Summer\")\n",
                "print(pred_summer[0], pred_summer[1], pred_summer[2])\n",
                "print(target_summer[0], target_summer[1], target_summer[2])\n",
                "print(pred_summer.mean(), pred_summer.std())\n",
                "\n",
                "\n",
                "\n",
                "# Call predict()\n",
                "pred_fall: np.ndarray = predict_linreg(df_features_fall.to_numpy(), beta_fall)\n",
                "\n",
                "# Change target to numpy array\n",
                "target_fall: np.ndarray = df_target_fall.to_numpy()\n",
                "\n",
                "print(\"Fall\")\n",
                "print(pred_fall[0], pred_fall[1], pred_fall[2])\n",
                "print(target_fall[0], target_fall[1], target_fall[2])\n",
                "print(pred_fall.mean(), pred_fall.std())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_winter[\"average_temp °c\"],target_winter)\n",
                "plt.scatter(df_features_winter[\"average_temp °c\"],pred_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_winter[\"humidity %\"],target_winter)\n",
                "plt.scatter(df_features_winter[\"humidity %\"],pred_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_winter[\"wind_speed km/h\"],target_winter)\n",
                "plt.scatter(df_features_winter[\"wind_speed km/h\"],pred_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_spring[\"average_temp °c\"],target_spring)\n",
                "plt.scatter(df_features_spring[\"average_temp °c\"],pred_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_spring[\"humidity %\"],target_spring)\n",
                "plt.scatter(df_features_spring[\"humidity %\"],pred_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_spring[\"wind_speed km/h\"],target_spring)\n",
                "plt.scatter(df_features_spring[\"wind_speed km/h\"],pred_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_summer[\"average_temp °c\"],target_summer)\n",
                "plt.scatter(df_features_summer[\"average_temp °c\"],pred_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_summer[\"humidity %\"],target_summer)\n",
                "plt.scatter(df_features_summer[\"humidity %\"],pred_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_summer[\"wind_speed km/h\"],target_summer)\n",
                "plt.scatter(df_features_summer[\"wind_speed km/h\"],pred_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_fall[\"average_temp °c\"],target_fall)\n",
                "plt.scatter(df_features_fall[\"average_temp °c\"],pred_fall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_fall[\"humidity %\"],target_fall)\n",
                "plt.scatter(df_features_fall[\"humidity %\"],pred_fall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_fall[\"wind_speed km/h\"],target_fall)\n",
                "plt.scatter(df_features_fall[\"wind_speed km/h\"],pred_fall)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "2unt7l8s45pvvfr8i0j0ka",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Evaluating the Model\n",
                "\n",
                "- Describe the metrics of your choice\n",
                "- Evaluate your model performance"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Splitting Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "cellIdentifier": "0pc6mmhipg0b5twb6ag1td"
            },
            "outputs": [],
            "source": [
                "# Split the data set into training and test\n",
                "df_features_train_winter, df_features_test_winter, df_target_train_winter, df_target_test_winter = split_data(df_features_winter, df_target_winter, random_state=100, test_size=0.3)\n",
                "# call build_model_linreg() function\n",
                "model_winter, J_storage_winter = build_model_linreg(df_features_train_winter, df_target_train_winter)\n",
                "# call the predict_linreg() method\n",
                "pred_winter: np.ndarray = predict_linreg(df_features_test_winter.to_numpy(), model_winter['beta'], model_winter['means'], model_winter['stds'])\n",
                "\n",
                "\n",
                "# Split the data set into training and test\n",
                "df_features_train_spring, df_features_test_spring, df_target_train_spring, df_target_test_spring = split_data(df_features_spring, df_target_spring, random_state=100, test_size=0.3)\n",
                "# call build_model_linreg() function\n",
                "model_spring, J_storage_spring = build_model_linreg(df_features_train_spring, df_target_train_spring)\n",
                "# call the predict_linreg() method\n",
                "pred_spring: np.ndarray = predict_linreg(df_features_test_spring.to_numpy(), model_spring['beta'], model_spring['means'], model_spring['stds'])\n",
                "\n",
                "\n",
                "# Split the data set into training and test\n",
                "df_features_train_summer, df_features_test_summer, df_target_train_summer, df_target_test_summer = split_data(df_features_summer, df_target_summer, random_state=100, test_size=0.3)\n",
                "# call build_model_linreg() function\n",
                "model_summer, J_storage_summer = build_model_linreg(df_features_train_summer, df_target_train_summer)\n",
                "# call the predict_linreg() method\n",
                "pred_summer: np.ndarray = predict_linreg(df_features_test_summer.to_numpy(), model_summer['beta'], model_summer['means'], model_summer['stds'])\n",
                "\n",
                "\n",
                "# Split the data set into training and test\n",
                "df_features_train_fall, df_features_test_fall, df_target_train_fall, df_target_test_fall = split_data(df_features_fall, df_target_fall, random_state=100, test_size=0.3)\n",
                "# call build_model_linreg() function\n",
                "model_fall, J_storage_fall = build_model_linreg(df_features_train_fall, df_target_train_fall)\n",
                "# call the predict_linreg() method\n",
                "pred_fall: np.ndarray = predict_linreg(df_features_test_fall.to_numpy(), model_fall['beta'], model_fall['means'], model_fall['stds'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_winter[\"average_temp °c\"], df_target_test_winter)\n",
                "plt.scatter(df_features_test_winter[\"average_temp °c\"], pred_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_winter[\"humidity %\"], df_target_test_winter)\n",
                "plt.scatter(df_features_test_winter[\"humidity %\"], pred_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_winter[\"wind_speed km/h\"], df_target_test_winter)\n",
                "plt.scatter(df_features_test_winter[\"wind_speed km/h\"], pred_winter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_spring[\"average_temp °c\"], df_target_test_spring)\n",
                "plt.scatter(df_features_test_spring[\"average_temp °c\"], pred_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_spring[\"humidity %\"], df_target_test_spring)\n",
                "plt.scatter(df_features_test_spring[\"humidity %\"], pred_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_spring[\"wind_speed km/h\"], df_target_test_spring)\n",
                "plt.scatter(df_features_test_spring[\"wind_speed km/h\"], pred_spring)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_summer[\"average_temp °c\"], df_target_test_summer)\n",
                "plt.scatter(df_features_test_summer[\"average_temp °c\"], pred_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_summer[\"humidity %\"], df_target_test_summer)\n",
                "plt.scatter(df_features_test_summer[\"humidity %\"], pred_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_summer[\"wind_speed km/h\"], df_target_test_summer)\n",
                "plt.scatter(df_features_test_summer[\"wind_speed km/h\"], pred_summer)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_fall[\"average_temp °c\"], df_target_test_fall)\n",
                "plt.scatter(df_features_test_fall[\"average_temp °c\"], pred_fall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_fall[\"humidity %\"], df_target_test_fall)\n",
                "plt.scatter(df_features_test_fall[\"humidity %\"], pred_fall)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test_fall[\"wind_speed km/h\"], df_target_test_fall)\n",
                "plt.scatter(df_features_test_fall[\"wind_speed km/h\"], pred_fall)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### R<sup>2</sup> Score (Coefficient of Determination)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target_winter: np.ndarray = df_target_test_winter.to_numpy()\n",
                "r2_winter: float = r2_score(target_winter, pred_winter)\n",
                "\n",
                "target_spring: np.ndarray = df_target_test_spring.to_numpy()\n",
                "r2_spring: float = r2_score(target_spring, pred_spring)\n",
                "\n",
                "target_summer: np.ndarray = df_target_test_summer.to_numpy()\n",
                "r2_summer: float = r2_score(target_summer, pred_summer)\n",
                "\n",
                "target_fall: np.ndarray = df_target_test_fall.to_numpy()\n",
                "r2_fall: float = r2_score(target_fall, pred_fall)\n",
                "\n",
                "print('r2_winter:', round(r2_winter,3))\n",
                "print('r2_spring:', round(r2_spring,3))\n",
                "print('r2_summer:', round(r2_summer,3))\n",
                "print('r2_fall:', round(r2_fall,3))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Mean Squared Error & Root Mean Squared Error"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mse_winter: float = mean_squared_error(target_winter, pred_winter)\n",
                "rmse_winter: float = math.sqrt(mse_winter)\n",
                "\n",
                "mse_spring: float = mean_squared_error(target_spring, pred_spring)\n",
                "rmse_spring: float = math.sqrt(mse_spring)\n",
                "\n",
                "mse_summer: float = mean_squared_error(target_summer, pred_summer)\n",
                "rmse_summer: float = math.sqrt(mse_summer)\n",
                "\n",
                "mse_fall: float = mean_squared_error(target_fall, pred_fall)\n",
                "rmse_fall: float = math.sqrt(mse_fall)\n",
                "\n",
                "print(f'mse_winter: {round(mse_winter,3)}, rmse_winter: {round(rmse_winter,3)}')\n",
                "print(f'mse_spring: {round(mse_spring,3)}, rmse_spring: {round(rmse_spring,3)}')\n",
                "print(f'mse_summer: {round(mse_summer,3)}, rmse_summer: {round(rmse_summer,3)}')\n",
                "print(f'mse_fall: {round(mse_fall,3)}, rmse_fall: {round(rmse_fall,3)}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "c9ywqckb64avu5qr8n5i2",
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "### Discussion and Analysis\n",
                "\n",
                "- Analyze the results of your metrics.\n",
                "\n",
                "R² tells us how much of the changes in energy usage can be explained by temperature, humidity, and wind.\n",
                "\n",
                "MSE and RMSE show how far off our predictions were from the real values (lower numbers = better).\n",
                "\n",
                "__For winter,__\n",
                "\n",
                "R<sup>2</sup>: 0.529, MSE: 0.327, RMSE: 0.572\n",
                "\n",
                "The model explains about 52.9% of the changes in energy use — that’s pretty decent.\n",
                "\n",
                "The average error is around 0.572 kWh, which is not too bad.\n",
                "\n",
                "This makes sense since people use more heating when it’s cold, and that’s affected by temperature and wind.\n",
                "\n",
                "__For spring,__\n",
                "\n",
                "R<sup>2</sup>: 0.764, MSE: 0.805, RMSE: 0.897\n",
                "\n",
                "The model does even better here — it explains 76.4% of the variation.\n",
                "\n",
                "But the average error is a bit higher, nearly 0.897 kWh.\n",
                "\n",
                "Spring weather can be unpredictable, so while the model gets the trend right, it’s not always exact.\n",
                "\n",
                "__For summer,__\n",
                "\n",
                "R<sup>2</sup>: 0.077, MSE: 0.104, RMSE: 0.322\n",
                "\n",
                "The model doesn’t perform well here — it only explains about 7.7% of energy use changes.\n",
                "\n",
                "The error is small (0.322 kWh), but that’s likely because energy use is low and steady in summer.\n",
                "\n",
                "It shows that weather isn’t a big factor for energy use during this time.\n",
                "\n",
                "__For fall,__\n",
                "\n",
                "R<sup>2</sup>: 0.813, MSE: 0.251, RMSE: 0.501\n",
                "\n",
                "This is the model’s best season — it explains over 81.3% of the changes.\n",
                "\n",
                "The average error is low at 0.501 kWh, meaning the predictions are quite accurate.\n",
                "\n",
                "Fall likely has more stable weather patterns, making energy use easier to predict."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cellIdentifier": "8pdxldawaydxaekkynrcgk"
            },
            "source": [
                "- Explain how does your analysis and machine learning help to solve your problem statement.\n",
                "\n",
                "Our goal was to figure out how weather affects household electricity use, and whether we can predict that use ahead of time.\n",
                "\n",
                "By using machine learning — specifically, Multiple Linear Regression — we were able to build a model that takes in temperature, humidity, and wind speed and gives an estimate of how much energy people are likely to use.\n",
                "\n",
                "This helps in a few important ways:\n",
                "\n",
                "It shows which seasons are easier to predict (like fall and spring) and which are harder (like summer).\n",
                "\n",
                "It gives energy providers a better idea of what to expect, so they can prepare in advance — for example, by making sure there’s enough supply during colder months.\n",
                "\n",
                "It supports better planning — city planners and policy-makers can use this kind of model to design smarter energy systems, reduce waste, and plan for future demand as the climate continues to change.\n",
                "\n",
                "In short, our model helps turn weather data into useful insights about energy use — and that’s a key step toward building more sustainable and efficient cities."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Conclusion\n",
                "\n",
                "The MLR model successfully demonstrates the influence of environmental factors on household energy consumption, with performance varying by season. While temperature, humidity, and wind speed strongly predict energy usage in fall and spring, they are less effective in summer — highlighting the need for additional variables or models for warmer months."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
